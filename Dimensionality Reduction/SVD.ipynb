{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVD\n",
    "\n",
    "> Source: <br/>\n",
    "> https://towardsdatascience.com/singular-value-decomposition-example-in-python-dab2507d85a0 <br/>\n",
    "> Statistical Learning with Sparsity, Trevor Hastie et al.\n",
    "\n",
    "- Principal component vectors are in order of directions which yield highest sample variance. Principal component vectors are orthogonal.\n",
    "- Methods either find directions of maximum variance or minimising reconstruction error associated with particular generative model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_digits\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.model_selection import train_test_split\n",
    "float_formatter = lambda x: \"%.2f\" % x\n",
    "np.set_printoptions(formatter={'float_kind':float_formatter})\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: (1797, 64)\n",
      "y: (1797,)\n"
     ]
    }
   ],
   "source": [
    "# 1797 8x8 pixel images, images presented as flattened 64-length vectors.\n",
    "X, y = load_digits(return_X_y=True)\n",
    "print('X: {}'.format(X.shape))\n",
    "print('y: {}'.format(y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into test and train set\n",
    "X_tr, X_te, y_tr, y_te = train_test_split(X,y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1a24382e10>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAECCAYAAADesWqHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAC9pJREFUeJzt3V+IXPUZxvHn6Zr4L5HEakUSMV0pARFq/hAqAWmTKLFKelNDAgqVluSiFUMLGntTvPNK7EURQtQKxoiJBoq01gQVEVptNsYaTSwaIm6irpJIjIUE49uLOSkxpO7Z7f5+OzPv9wNLZndn5/ntbp45Z2bPnNcRIQC5fGuyFwCgPooPJETxgYQoPpAQxQcSovhAQl1RfNvLbb9j+13b6wtnPWJ7xPaekjmn5V1h+0Xbe22/Zfuuwnnn2X7N9htN3n0l85rMAduv2362dFaTd8D2m7Z3295ZOGuG7a229zW/w+sKZs1tvqdTb0dtrysSFhGT+iZpQNJ7kgYlTZX0hqSrC+ZdL2m+pD2Vvr/LJc1vLk+X9K/C358lTWsuT5H0qqQfFP4efy3pCUnPVvqZHpB0SaWsxyT9ork8VdKMSrkDkj6SdGWJ2++GLf4iSe9GxP6IOCHpSUk/KRUWES9LOlzq9s+S92FE7Goufy5pr6RZBfMiIo41705p3oodpWV7tqSbJW0slTFZbF+kzobiYUmKiBMR8Vml+KWS3ouI90vceDcUf5akD057f1gFizGZbM+RNE+drXDJnAHbuyWNSNoeESXzHpR0t6SvCmacKSQ9b3vI9pqCOYOSPpH0aPNQZqPtCwvmnW6VpM2lbrwbiu+zfKzvjiO2PU3S05LWRcTRklkRcTIirpU0W9Ii29eUyLF9i6SRiBgqcfvfYHFEzJd0k6Rf2r6+UM456jwsfCgi5kn6QlLR56AkyfZUSSskbSmV0Q3FH5Z0xWnvz5Z0aJLWUoTtKeqUflNEPFMrt9ktfUnS8kIRiyWtsH1AnYdoS2w/XijrvyLiUPPviKRt6jxcLGFY0vBpe0xb1bkjKO0mSbsi4uNSAd1Q/H9I+p7t7zb3dKsk/WmS1zRhbFudx4h7I+KBCnmX2p7RXD5f0jJJ+0pkRcS9ETE7Iuao83t7ISJuK5F1iu0LbU8/dVnSjZKK/IUmIj6S9IHtuc2Hlkp6u0TWGVar4G6+1NmVmVQR8aXtX0n6qzrPZD4SEW+VyrO9WdIPJV1ie1jS7yLi4VJ56mwVb5f0ZvO4W5J+GxF/LpR3uaTHbA+oc8f+VERU+TNbJZdJ2ta5P9U5kp6IiOcK5t0paVOzUdov6Y6CWbJ9gaQbJK0tmtP86QBAIt2wqw+gMooPJETxgYQoPpAQxQcS6qriFz78ctKyyCOv2/K6qviSav5wq/4iySOvm/K6rfgAKihyAI/tvj4qaObMmWP+muPHj+vcc88dV96sWWN/seLhw4d18cUXjyvv6NGxv4bo2LFjmjZt2rjyDh48OOaviQg1R++N2cmTJ8f1db0iIkb9wUz6Ibu9aNmyZVXz7r///qp5O3bsqJq3fn3xF7x9zZEjR6rmdSN29YGEKD6QEMUHEqL4QEIUH0iI4gMJUXwgIYoPJNSq+DVHXAEob9TiNydt/IM6p/y9WtJq21eXXhiActps8auOuAJQXpvipxlxBWTR5kU6rUZcNScOqP2aZQDj0Kb4rUZcRcQGSRuk/n9ZLtDr2uzq9/WIKyCjUbf4tUdcASiv1Yk4mjlvpWa9AaiMI/eAhCg+kBDFBxKi+EBCFB9IiOIDCVF8ICGKDyTEJJ1xqD3ZZnBwsGreeEaE/T8OHz5cNW/lypVV87Zs2VI1rw22+EBCFB9IiOIDCVF8ICGKDyRE8YGEKD6QEMUHEqL4QEIUH0iozQitR2yP2N5TY0EAymuzxf+jpOWF1wGgolGLHxEvS6r7KgoARfEYH0howl6Wy+w8oHdMWPGZnQf0Dnb1gYTa/Dlvs6S/SZpre9j2z8svC0BJbYZmrq6xEAD1sKsPJETxgYQoPpAQxQcSovhAQhQfSIjiAwlRfCChvpidt2DBgqp5tWfZXXXVVVXz9u/fXzVv+/btVfNq/39hdh6ArkDxgYQoPpAQxQcSovhAQhQfSIjiAwlRfCAhig8kRPGBhNqcbPMK2y/a3mv7Ldt31VgYgHLaHKv/paTfRMQu29MlDdneHhFvF14bgELazM77MCJ2NZc/l7RX0qzSCwNQzpge49ueI2mepFdLLAZAHa1flmt7mqSnJa2LiKNn+Tyz84Ae0ar4tqeoU/pNEfHM2a7D7Dygd7R5Vt+SHpa0NyIeKL8kAKW1eYy/WNLtkpbY3t28/bjwugAU1GZ23iuSXGEtACrhyD0gIYoPJETxgYQoPpAQxQcSovhAQhQfSIjiAwn1xey8mTNnVs0bGhqqmld7ll1ttX+eYIsPpETxgYQoPpAQxQcSovhAQhQfSIjiAwlRfCAhig8kRPGBhNqcZfc826/ZfqOZnXdfjYUBKKfNsfrHJS2JiGPN+fVfsf2XiPh74bUBKKTNWXZD0rHm3SnNGwMzgB7W6jG+7QHbuyWNSNoeEczOA3pYq+JHxMmIuFbSbEmLbF9z5nVsr7G90/bOiV4kgIk1pmf1I+IzSS9JWn6Wz22IiIURsXCC1gagkDbP6l9qe0Zz+XxJyyTtK70wAOW0eVb/ckmP2R5Q547iqYh4tuyyAJTU5ln9f0qaV2EtACrhyD0gIYoPJETxgYQoPpAQxQcSovhAQhQfSIjiAwkxO28cduzYUTWv39X+/R05cqRqXjdiiw8kRPGBhCg+kBDFBxKi+EBCFB9IiOIDCVF8ICGKDyRE8YGEWhe/Garxum1OtAn0uLFs8e+StLfUQgDU03aE1mxJN0vaWHY5AGpou8V/UNLdkr4quBYAlbSZpHOLpJGIGBrleszOA3pEmy3+YkkrbB+Q9KSkJbYfP/NKzM4DeseoxY+IeyNidkTMkbRK0gsRcVvxlQEohr/jAwmN6dRbEfGSOmOyAfQwtvhAQhQfSIjiAwlRfCAhig8kRPGBhCg+kBDFBxLqi9l5tWehLViwoGpebbVn2dX+eW7ZsqVqXjdiiw8kRPGBhCg+kBDFBxKi+EBCFB9IiOIDCVF8ICGKDyRE8YGEWh2y25xa+3NJJyV9ySm0gd42lmP1fxQRnxZbCYBq2NUHEmpb/JD0vO0h22tKLghAeW139RdHxCHb35G03fa+iHj59Cs0dwjcKQA9oNUWPyIONf+OSNomadFZrsPsPKBHtJmWe6Ht6acuS7pR0p7SCwNQTptd/cskbbN96vpPRMRzRVcFoKhRix8R+yV9v8JaAFTCn/OAhCg+kBDFBxKi+EBCFB9IiOIDCVF8ICGKDyTkiJj4G7Un/ka/weDgYM047dy5s2re2rVrq+bdeuutVfNq//4WLuzvl5NEhEe7Dlt8ICGKDyRE8YGEKD6QEMUHEqL4QEIUH0iI4gMJUXwgIYoPJNSq+LZn2N5qe5/tvbavK70wAOW0Hajxe0nPRcRPbU+VdEHBNQEobNTi275I0vWSfiZJEXFC0omyywJQUptd/UFJn0h61Pbrtjc2gzW+xvYa2ztt133pGoAxa1P8cyTNl/RQRMyT9IWk9WdeiRFaQO9oU/xhScMR8Wrz/lZ17ggA9KhRix8RH0n6wPbc5kNLJb1ddFUAimr7rP6dkjY1z+jvl3RHuSUBKK1V8SNityQeuwN9giP3gIQoPpAQxQcSovhAQhQfSIjiAwlRfCAhig8k1Bez82pbs2ZN1bx77rmnat7Q0FDVvJUrV1bN63fMzgNwVhQfSIjiAwlRfCAhig8kRPGBhCg+kBDFBxKi+EBCoxbf9lzbu097O2p7XY3FAShj1HPuRcQ7kq6VJNsDkg5K2lZ4XQAKGuuu/lJJ70XE+yUWA6COsRZ/laTNJRYCoJ7WxW/Oqb9C0pb/8Xlm5wE9ou1ADUm6SdKuiPj4bJ+MiA2SNkj9/7JcoNeNZVd/tdjNB/pCq+LbvkDSDZKeKbscADW0HaH1b0nfLrwWAJVw5B6QEMUHEqL4QEIUH0iI4gMJUXwgIYoPJETxgYQoPpBQqdl5n0gaz2v2L5H06QQvpxuyyCOvVt6VEXHpaFcqUvzxsr0zIhb2WxZ55HVbHrv6QEIUH0io24q/oU+zyCOvq/K66jE+gDq6bYsPoAKKDyRE8YGEKD6QEMUHEvoPF72a45tCHDcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Example of image\n",
    "image = X[0]\n",
    "image = image.reshape((8, 8))\n",
    "plt.matshow(image, cmap = 'gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> numpy.linalg.svd is a wrapper around xGESDD in LAPACK. Singular value decompositions proceed in two stages. First, the matrix to be decomposed is reduced to bidiagonal form. The algorithm used to reduce to bidiagonal form in LAPACK is probably the Lawson-Hanson-Chan algorithm, and it does use QR factorization at one point. Lecture 31 in Numerical Linear Algebra by Trefethen and Bau gives an overview of this process. Then, xGESDD uses a divide-and-conquer algorithm to calculate the singular values and left and right singular vectors from the bidiagonal matrix. To get background on this step, you'll need to consult Matrix Computations by Golub and Van Loan, or Applied Numerical Linear Algebra by Jim Demmel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low Rank Image Shape: (8, 8)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1a243c1278>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Performing SVD directly on image\n",
    "# image: m x n, U: m x m, s: min(n, m) vector, V: n x n\n",
    "U, s, Vh = np.linalg.svd(image)\n",
    "\n",
    "# Reduced rank Sigma (S: m x n)\n",
    "S = np.zeros((image.shape[0], image.shape[1]))\n",
    "S[:s.shape[0], :s.shape[0]] = np.diag(s)\n",
    "n_component = 2\n",
    "\n",
    "# S: m x n_component\n",
    "S = S[:, :n_component]\n",
    "\n",
    "# First n_component rows of VT. Rows of VT are principal component directions.\n",
    "Vh = Vh[:n_component, :]\n",
    "\n",
    "# Reconstruct low rank approximation of matrix\n",
    "A = U.dot(S.dot(Vh))\n",
    "print('Low Rank Image Shape: {}'.format(A.shape))\n",
    "plt.matshow(A, cmap = 'gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note in the operations above, the entire left principal component vector matrix needs to be retained to reconstruct the low rank image. Its size would be similar to the original image matrix if m is similar to n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce(x_, arr):\n",
    "    # Performing SVD directly on image\n",
    "    x = x_.reshape((8, 8))\n",
    "    # image: m x n, U: m x m, s: min(n, m) vector, V: n x n\n",
    "    U, s, Vh = np.linalg.svd(x)\n",
    "\n",
    "    # Reduced rank Sigma (S: m x n)\n",
    "    S = np.zeros((image.shape[0], image.shape[1]))\n",
    "    S[:s.shape[0], :s.shape[0]] = np.diag(s)\n",
    "    n_component = 2\n",
    "\n",
    "    # S: m x n_component\n",
    "    S = S[:, :n_component]\n",
    "\n",
    "    # First n_component rows of VT. Rows of VT are principal component directions.\n",
    "    Vh = Vh[:n_component, :]\n",
    "\n",
    "    # Reconstruct low rank approximation of matrix\n",
    "    P = U.dot(S)\n",
    "    \n",
    "    if len(arr) == 0:\n",
    "        arr = np.array([P.flatten()])\n",
    "    else:\n",
    "        arr = np.vstack((arr, P.flatten()))\n",
    "    return arr\n",
    "\n",
    "def reduce2(x_, arr):\n",
    "    svd = TruncatedSVD(n_components=2)\n",
    "    x = x_.reshape((8, 8))\n",
    "    P = svd.fit_transform(x)\n",
    "    \n",
    "    if len(arr) == 0:\n",
    "        arr = np.array([P.flatten()])\n",
    "    else:\n",
    "        arr = np.vstack((arr, P.flatten()))\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_low_tr Shape: (1347, 16)\n",
      "X_low_te Shape: (450, 16)\n"
     ]
    }
   ],
   "source": [
    "X_low_tr = np.array([])\n",
    "X_low_te = np.array([])\n",
    "for x_ in X_tr:\n",
    "    X_low_tr = reduce(x_, X_low_tr)\n",
    "for x_ in X_te:\n",
    "    X_low_te = reduce(x_, X_low_te)\n",
    "\n",
    "print('X_low_tr Shape: {}'.format(X_low_tr.shape))\n",
    "print('X_low_te Shape: {}'.format(X_low_te.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_low2_tr Shape: (1347, 16)\n",
      "X_low2_te Shape: (450, 16)\n"
     ]
    }
   ],
   "source": [
    "X_low2_tr = np.array([])\n",
    "X_low2_te = np.array([])\n",
    "for x_ in X_tr:\n",
    "    X_low2_tr = reduce2(x_, X_low2_tr)\n",
    "for x_ in X_te:\n",
    "    X_low2_te = reduce2(x_, X_low2_te)\n",
    "\n",
    "print('X_low2_tr Shape: {}'.format(X_low2_tr.shape))\n",
    "print('X_low2_te Shape: {}'.format(X_low2_te.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce3(X_tr_, n_component=None, V=None):\n",
    "    if V is None:\n",
    "        # image: m x n, U: m x m, s: min(n, m) vector, V: n x n\n",
    "        U, s, Vh = np.linalg.svd(X_tr_)\n",
    "\n",
    "        # First n_component rows of VT. Rows of VT are principal component directions.\n",
    "        Vh = Vh[:n_component, :]\n",
    "\n",
    "        # Reduced Data\n",
    "        return X_tr_.dot(Vh.T), Vh.T\n",
    "    else:\n",
    "        return X_tr_.dot(V)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_reduced_tr Shape: (1347, 16)\n",
      "X_reduced_te Shape: (450, 16)\n"
     ]
    }
   ],
   "source": [
    "X_reduced_tr, V = reduce3(X_tr, 16)\n",
    "X_reduced_te = reduce3(X_te, V=V)\n",
    "print('X_reduced_tr Shape: {}'.format(X_reduced_tr.shape))\n",
    "print('X_reduced_te Shape: {}'.format(X_reduced_te.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rf_model(model, X_tr_, X_te_, y_tr_, y_te_):\n",
    "    rf = RandomForestClassifier(n_estimators=500, random_state=42)\n",
    "    rf.fit(X_tr_, y_tr_)\n",
    "    predictions = rf.predict(X_te_)\n",
    "    accuracy = round((sum(predictions == y_te_)/y_te_.shape[0]) * 100, 2)\n",
    "    print(model + ' Accuracy: {}%'.format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data Accuracy: 97.56%\n"
     ]
    }
   ],
   "source": [
    "rf_model('Original Data', X_tr, X_te, y_tr, y_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numpy SVD on individual images, Accuracy: 91.11%\n"
     ]
    }
   ],
   "source": [
    "rf_model('Numpy SVD on individual images,', X_low_tr, X_low_te, y_tr, y_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Truncated SVD on individual images, Accuracy: 92.67%\n"
     ]
    }
   ],
   "source": [
    "rf_model('Truncated SVD on individual images,', X_low2_tr, X_low2_te, y_tr, y_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVD on training set with principal directions preserved from training, Accuracy: 97.11%\n"
     ]
    }
   ],
   "source": [
    "rf_model('SVD on training set with principal directions preserved from training,', X_reduced_tr, X_reduced_te, y_tr, y_te)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This analysis reveals that SVD can be used as a means to reduce the number of features required to create an effective classifier for handwritten digits. Two different methods of dimensionality reduction were compared in the analysis:\n",
    "\n",
    "- Using SVD to reduce dimensions of training set and then using principal direction vectors derrived from training set to reduce test set.\n",
    "- Using SVD to independently reduce dimensions of each image feature vector, by preserving only two features per pixel row in image.\n",
    "\n",
    "Both results yielded high levels of accuracy, with the method where SVD was applied on the whole training set yielding results that were almost identical to the accuracy of the classifier trained on the orginal data. Given $m > n$ for a $m \\times n$ matrix, the worst case algorithmic complexity of applying SVD is $O(mn^2)$. In the method above where SVD is applied independently to each image feature vector, this complexity reduces to $O(mn^{1.5})$. For large values of $n$ this can translate into significant time savings when training a model. Furthermore, this method is also advantageous for online learning workflows as new data can be reduced independently before being included in training sets. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
